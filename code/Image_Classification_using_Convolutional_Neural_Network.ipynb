{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification using Convolutional Neural Network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGDvddLDR-yi"
      },
      "source": [
        "<h1 align=center><font size = 6>Image Classification using Convolutional Neural Network</font></h1>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr1HXYH4USUw"
      },
      "source": [
        "<h3><strong>Done by</strong></h3>\n",
        "<p>Firda Anindita Latifah</p>\n",
        "<p>firdaaninditalatifah@gmail.com</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogkmFMLl72P-"
      },
      "source": [
        "#Load dataset rockpaperscissors from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFRgv-HDgxyF"
      },
      "source": [
        "#Changing the working directory\n",
        "\n",
        "%cd /content/gdrive/My Drive/Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3oQPyxLikU2"
      },
      "source": [
        "#Extract from zip and define the directory\n",
        "\n",
        "import zipfile,os\n",
        "\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images'\n",
        "os.listdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT_oNLb1NlsO"
      },
      "source": [
        "#Image augmentation and split data into training and validation (6/4)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  rotation_range=20,\n",
        "  horizontal_flip=True,\n",
        "  shear_range = 0.2,\n",
        "  fill_mode = 'nearest',\n",
        "  validation_split=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQMzKyM8OI82"
      },
      "source": [
        "#Prepare the training and validation dataset\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  base_dir,\n",
        "  target_size=(150, 150),  \n",
        "  batch_size=32,\n",
        "  class_mode='categorical',\n",
        "  subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "  base_dir, \n",
        "  target_size=(150, 150), \n",
        "  batch_size=32, \n",
        "  class_mode='categorical',\n",
        "  subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8Ba14jDP_tb"
      },
      "source": [
        "#Define CNN Model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "  MaxPooling2D(2, 2),\n",
        "  Conv2D(64, (3,3), activation='relu'),\n",
        "  MaxPooling2D(2,2),\n",
        "  Conv2D(128, (3,3), activation='relu'),\n",
        "  MaxPooling2D(2,2),\n",
        "  Conv2D(512, (3,3), activation='relu'),\n",
        "  MaxPooling2D(2,2),\n",
        "  Flatten(),\n",
        "  Dropout(0.5),\n",
        "  Dense(512, activation='relu'),\n",
        "  Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGd50C7Lds3C"
      },
      "source": [
        "#Define callback function to stop the epoch after the accuracy is greater than 96%\n",
        "\n",
        "class Call(tf.keras.callbacks.Callback): \n",
        "  def on_epoch_end(self, epoch, logs={}): \n",
        "    if(logs.get('accuracy') > 0.96 and logs.get('val_accuracy') > 0.96):\n",
        "      print(\"\\nAccuracy > 96%\") \n",
        "      self.model.stop_training = True \n",
        " \n",
        "callbacks = Call()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOP_2gkWatCk"
      },
      "source": [
        "#Compile model using 'adam' optimizer and 'categorical_crossentropy' loss function\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
        "  loss='categorical_crossentropy', \n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW7PD4RAUXnP"
      },
      "source": [
        "#Train the model\n",
        "\n",
        "history = model.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch=40,\n",
        "  epochs=15,\n",
        "  validation_data=validation_generator, \n",
        "  validation_steps=25,\n",
        "  verbose=2,\n",
        "  callbacks=[callbacks]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSMQ3sX7jHtf"
      },
      "source": [
        "#Accuration and loss plot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy'] \n",
        "loss = history.history['loss'] \n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy') \n",
        "plt.title('Training and validation accuracy') \n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim((0,1))\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim((0,1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQwJPYzxZEWR"
      },
      "source": [
        "#Predict the new data\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for test in uploaded.keys():\n",
        "  path = test\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  output_class = np.argmax(classes)\n",
        "\n",
        "  print(test)\n",
        "  if output_class==0:\n",
        "    print('This is a paper')\n",
        "  elif output_class==1:\n",
        "    print('This is a rock')\n",
        "  else:\n",
        "    print('This is a scissors')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}